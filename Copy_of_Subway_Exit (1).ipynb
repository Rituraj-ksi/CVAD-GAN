{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFX79eX69HIt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmZ_3-Lr9J6e",
    "outputId": "036d1c16-76ba-474d-ec27-c8d91a83c450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyS-ldz29KzJ",
    "outputId": "a7b55255-d8a9-45ac-a523-6e24a9258b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "'Colab Notebooks'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!ls \"/content/drive/My Drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwExYet59uxk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaT2FLuW9u0a"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "#import mxnet as mx\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "#from mxnet import gluon,nd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# create dataloader (batch_size, 1, 100, 100)\n",
    "def create_dataset(path, batch_size, shuffle):\n",
    "  files = glob.glob(path)\n",
    "  data = np.zeros((len(files),1,160,160))\n",
    "\n",
    "  for idx, filename in enumerate(files):\n",
    "    im = Image.open(filename)\n",
    "    im = ImageOps.grayscale(im)\n",
    "    im = im.resize((160,160))\n",
    "    data[idx,0,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "\n",
    "  #dataset = gluon.data.ArrayDataset(mx.nd.array(data, dtype=np.float32))\n",
    "  #dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch=\"rollover\", shuffle=shuffle)\n",
    "  dataloader = tf.data.Dataset.from_tensor_slices(data).batch(batch_size)\n",
    "\n",
    "  return dataloader\n",
    "\n",
    "# create dataloader (batch_size, 10, 227, 227)\n",
    "def create_dataset_stacked_images(path, batch_size, shuffle, augment=True):\n",
    "\n",
    "  files = sorted(glob.glob(path))\n",
    "  if augment:\n",
    "    files = files + files[2:] + files[4:] + files[6:] + files[8:]\n",
    "  data = np.zeros((int(len(files)/10),10,227,227))\n",
    "  i, idx = 0, 0\n",
    "  for filename in files:\n",
    "    im = Image.open(filename)\n",
    "    im = ImageOps.grayscale(im)\n",
    "    im = im.resize((227,227))\n",
    "    data[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "    i = i + 1\n",
    "    if i > 9:\n",
    "      i = 0\n",
    "      idx = idx + 1\n",
    "  #dataset = gluon.data.ArrayDataset(mx.nd.array(data, dtype=np.float32))\n",
    "  #dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch=\"rollover\", shuffle=shuffle)\n",
    "  dataloader = tf.data.Dataset.from_tensor_slices(data).batch(batch_size)\n",
    "\n",
    "  return dataloader\n",
    "\n",
    "# perform inference and plot results\n",
    "def plot_images(path, model, output_path=\"img\", stacked=False, lstm=False):\n",
    "\n",
    "  if not stacked:\n",
    "    dataloader = create_dataset(path, batch_size=1, shuffle=False)\n",
    "  else:\n",
    "    dataloader = create_dataset_stacked_images(path, batch_size=1, shuffle=False, augment=False)\n",
    "\n",
    "  counter = 0\n",
    "  #model.load_parameters(params_file, ctx=ctx)\n",
    "\n",
    "  try:\n",
    "    os.mkdir(output_path,exist_ok=True)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  for image in dataloader:\n",
    "\n",
    "    # perform inference\n",
    "    #image = image.as_in_context(ctx)\n",
    "    #if not lstm:\n",
    "      #image_batch1=tf.transpose(image_batch,perm=[0,2,3,1])\n",
    "      #reconstructed = model(image)\n",
    "    #else:\n",
    "      #states = model.temporal_encoder.begin_state(batch_size=1, ctx=ctx)\n",
    "      #reconstructed, states = model(image, states)\n",
    "    #compute difference between reconstructed image and input image\n",
    "    #reconstructed = reconstructed.asnumpy()\n",
    "    #image = image.asnumpy()\n",
    "    #diff = np.abs(reconstructed-image)\n",
    "\n",
    "    if not lstm:\n",
    "      image_batch1=tf.transpose(image,perm=[0,2,3,1])\n",
    "      reconstructed = model(image_batch1)\n",
    "    else:\n",
    "      states = model.temporal_encoder.begin_state(batch_size=1, ctx=ctx)\n",
    "      reconstructed, states = model(image, states)\n",
    "    #compute difference between reconstructed image and input image\n",
    "    reconstructed = reconstructed.numpy()#tf.make_ndarray(reconstructed)\n",
    "    image_batch1 = image_batch1.numpy()\n",
    "    diff = np.abs(reconstructed-image_batch1)\n",
    "    reconstructed=tf.transpose(reconstructed,perm=[0,3,1,2])\n",
    "    diff=np.transpose(diff,(0,3,1,2))\n",
    "    #image\n",
    "    # in case of stacked frames, we need to compute the regularity score per pixel\n",
    "    if stacked:\n",
    "       image    = np.sum(image, axis=1, keepdims=True)\n",
    "       reconstructed = np.sum(reconstructed, axis=1, keepdims=True)\n",
    "       diff_max = np.max(diff, axis=1)\n",
    "       diff_min = np.min(diff, axis=1)\n",
    "       regularity = diff_max - diff_min\n",
    "       # perform convolution on regularity matrix\n",
    "       H = signal.convolve2d(regularity[0,:,:], np.ones((4,4)), mode='same')\n",
    "    else:\n",
    "      # perform convolution on diff matrix\n",
    "      H = signal.convolve2d(diff[0,0,:,:], np.ones((4,4)), mode='same')\n",
    "\n",
    "    # if neighboring pixels are anamolous, then mark the current pixel\n",
    "    x,y = np.where(H > 4)\n",
    "\n",
    "    # plt input image, reconstructed image and difference between both\n",
    "    fig, (ax0, ax1, ax2,ax3) = plt.subplots(ncols=4, figsize=(10, 5))\n",
    "    ax0.set_axis_off()\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    ax0.imshow(image[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax0.set_title('input image')\n",
    "    ax1.imshow(reconstructed[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax1.set_title('reconstructed image')\n",
    "    ax2.imshow(diff[0,0,:,:], cmap=plt.cm.viridis, vmin=0, vmax=1, interpolation='nearest')\n",
    "    ax2.set_title('diff ')\n",
    "    ax3.imshow(image[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax3.scatter(y,x,color='red',s=0.3)\n",
    "    ax3.set_title('anomalies')\n",
    "    plt.axis('off')\n",
    "\n",
    "     # save figure\n",
    "    counter = counter + 1\n",
    "    fig.savefig(output_path + \"/\" + str(counter) + '.png', bbox_inches = 'tight', pad_inches = 0.5)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95wF92yP9u5k"
   },
   "outputs": [],
   "source": [
    "def hms_string(sec_elapsed):\n",
    "  h = int(sec_elapsed / (60 * 60))\n",
    "  m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "  s = sec_elapsed % 60\n",
    "  return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dhO9y4M9u8m"
   },
   "outputs": [],
   "source": [
    "train_directory='/*'\n",
    "test_directory='/*'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8Xx-QW6-opA"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "li=glob.glob(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui7uPNb2-orx"
   },
   "outputs": [],
   "source": [
    "\n",
    "output= plot_images(test_directory,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMPU3xso-oub"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxTy7YQz-ow-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLrfewts-ozj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNDpDbeN-o1z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2EjwLWB-o9v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9LTbCkr-7kh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vFIu8GQ-7qf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djXCs3sv-7tW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8-MmxdQ-7wK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edJNKzoC-7zk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
