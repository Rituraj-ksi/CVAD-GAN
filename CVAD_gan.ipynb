{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zUpQaIBf5EoV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from tensorflow.keras.datasets.mnist import load_data as load_data\n",
    "import random\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GaussianNoise, Conv2D, Conv2DTranspose, BatchNormalization, MaxPool2D, Flatten, Dense, Reshape, UpSampling2D, LeakyReLU, ReLU, Input, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jOmLqIeq5NxL"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "#import mxnet as mx\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "#from mxnet import gluon,nd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# create dataloader (batch_size, 1, 100, 100)\n",
    "def create_dataset(path, batch_size, shuffle):\n",
    "  files = glob.glob(path)\n",
    "  data = np.zeros((len(files),1,160,160))\n",
    "\n",
    "  for idx, filename in enumerate(files):\n",
    "    im = Image.open(filename)\n",
    "    #im = ImageOps.grayscale(im)\n",
    "    im = im.resize((160,160))\n",
    "    data[idx,0,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "\n",
    "  #dataset = gluon.data.ArrayDataset(mx.nd.array(data, dtype=np.float32))\n",
    "  #dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch=\"rollover\", shuffle=shuffle)\n",
    "  dataloader = tf.data.Dataset.from_tensor_slices(data).batch(batch_size)\n",
    "\n",
    "  return dataloader\n",
    "\n",
    "# create dataloader (batch_size, 10, 227, 227)\n",
    "def create_dataset_stacked_images(path, batch_size, shuffle, augment=True):\n",
    "  \n",
    "  files = sorted(glob.glob(path))\n",
    "  if augment:\n",
    "    files = files + files[2:] + files[4:] + files[6:] + files[8:]\n",
    "  data = np.zeros((int(len(files)/10),10,160,160))\n",
    "  i, idx = 0, 0\n",
    "  for filename in files:\n",
    "    im = Image.open(filename)\n",
    "    im = im.resize((160,160))\n",
    "    data[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "    i = i + 1\n",
    "    if i > 9: \n",
    "      i = 0\n",
    "      idx = idx + 1\n",
    "  #dataset = gluon.data.ArrayDataset(mx.nd.array(data, dtype=np.float32))\n",
    "  #dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch=\"rollover\", shuffle=shuffle)\n",
    "  dataloader = tf.data.Dataset.from_tensor_slices(data).batch(batch_size)\n",
    "\n",
    "  return dataloader\n",
    "\n",
    "# perform inference and plot results\n",
    "def plot_images(path, model, output_path=\"img\", stacked=False, lstm=False):\n",
    "\n",
    "  if not stacked:\n",
    "    dataloader = create_dataset(path, batch_size=1, shuffle=False)\n",
    "  else:\n",
    "    dataloader = create_dataset_stacked_images(path, batch_size=1, shuffle=False, augment=False)\n",
    "\n",
    "  counter = 0\n",
    "  #model.load_parameters(params_file, ctx=ctx)\n",
    "  \n",
    "  try:\n",
    "    os.mkdir(output_path,exist_ok=True)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  for image in dataloader:\n",
    "    \n",
    "    # perform inference\n",
    "    #image = image.as_in_context(ctx)\n",
    "    #if not lstm:\n",
    "      #image_batch1=tf.transpose(image_batch,perm=[0,2,3,1])\n",
    "      #reconstructed = model(image)\n",
    "    #else:\n",
    "      #states = model.temporal_encoder.begin_state(batch_size=1, ctx=ctx)\n",
    "      #reconstructed, states = model(image, states)\n",
    "    #compute difference between reconstructed image and input image \n",
    "    #reconstructed = reconstructed.asnumpy()\n",
    "    #image = image.asnumpy()\n",
    "    #diff = np.abs(reconstructed-image)\n",
    "\n",
    "    if not lstm:\n",
    "      image_batch1=tf.transpose(image,perm=[0,2,3,1])\n",
    "      reconstructed = model(image_batch1)\n",
    "    else:\n",
    "      states = model.temporal_encoder.begin_state(batch_size=1, ctx=ctx)\n",
    "      reconstructed, states = model(image, states)\n",
    "    #compute difference between reconstructed image and input image \n",
    "    reconstructed = reconstructed.numpy()#tf.make_ndarray(reconstructed)\n",
    "    image_batch1 = image_batch1.numpy()\n",
    "    diff = np.abs(reconstructed-image_batch1)\n",
    "    reconstructed=tf.transpose(reconstructed,perm=[0,3,1,2])\n",
    "    diff=np.transpose(diff,(0,3,1,2))\n",
    "    #image\n",
    "    # in case of stacked frames, we need to compute the regularity score per pixel\n",
    "    if stacked:\n",
    "       image    = np.sum(image, axis=1, keepdims=True)\n",
    "       reconstructed = np.sum(reconstructed, axis=1, keepdims=True)\n",
    "       diff_max = np.max(diff, axis=1)\n",
    "       diff_min = np.min(diff, axis=1)\n",
    "       regularity = diff_max - diff_min\n",
    "       # perform convolution on regularity matrix\n",
    "       H = signal.convolve2d(regularity[0,:,:], np.ones((4,4)), mode='same')\n",
    "    else:\n",
    "      # perform convolution on diff matrix\n",
    "      H = signal.convolve2d(diff[0,0,:,:], np.ones((4,4)), mode='same')\n",
    "    \n",
    "    # if neighboring pixels are anamolous, then mark the current pixel\n",
    "    x,y = np.where(H > 4)\n",
    "\n",
    "    # plt input image, reconstructed image and difference between both\n",
    "    fig, (ax0, ax1, ax2,ax3) = plt.subplots(ncols=4, figsize=(10, 5))\n",
    "    ax0.set_axis_off()\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    ax0.imshow(image[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax0.set_title('input image')\n",
    "    ax1.imshow(reconstructed[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax1.set_title('reconstructed image')\n",
    "    ax2.imshow(diff[0,0,:,:], cmap=plt.cm.viridis, vmin=0, vmax=1, interpolation='nearest')\n",
    "    ax2.set_title('diff ')\n",
    "    ax3.imshow(image[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax3.scatter(y,x,color='red',s=0.3)\n",
    "    ax3.set_title('anomalies')\n",
    "    plt.axis('off')\n",
    "    \n",
    "     # save figure\n",
    "    counter = counter + 1\n",
    "    fig.savefig(output_path + \"/\" + str(counter) + '.png', bbox_inches = 'tight', pad_inches = 0.5)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lCsPDqpZ7sL8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "def hms_string(sec_elapsed):\n",
    "  h = int(sec_elapsed / (60 * 60))\n",
    "  m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "  s = sec_elapsed % 60\n",
    "  return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "F-umz6M4BU_S"
   },
   "outputs": [],
   "source": [
    "def makeEncoder(inputShape, outputUnits):\n",
    "  \n",
    "  # Encoder\n",
    "  encoder = Sequential()\n",
    "\n",
    "  # Adding Gaussian Noise\n",
    "  encoder.add(GaussianNoise(stddev = 0, input_shape = inputShape))\n",
    "  \n",
    "  # Convolution Block\n",
    "  encoder.add(Conv2D(filters = 32, kernel_size = (5,5), strides=(2, 2), padding = \"same\"))\n",
    "  encoder.add(BatchNormalization())\n",
    "\n",
    "  encoder.add(LeakyReLU(alpha = 0.3))\n",
    "  #encoder.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "  # Convolution Block\n",
    "  encoder.add(Conv2D(filters = 64, kernel_size = (5,5), strides=(2, 2), padding = \"same\"))\n",
    "  encoder.add(BatchNormalization())\n",
    "  encoder.add(LeakyReLU(alpha = 0.3))\n",
    "  #encoder.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "  # Convolution Block\n",
    "  encoder.add(Conv2D(filters = 128, kernel_size = (5,5), strides=(2,2), padding = \"same\"))\n",
    "  encoder.add(BatchNormalization())\n",
    "  encoder.add(LeakyReLU(alpha = 0.3))\n",
    "  #encoder.add(MaxPool2D(pool_size = (2,2))) \n",
    "\n",
    "  encoder.add(Conv2D(filters = 256, kernel_size = (5,5), strides=(2,2), padding = \"same\"))\n",
    "  encoder.add(BatchNormalization())\n",
    "  encoder.add(LeakyReLU(alpha = 0.3))\n",
    "  encoder.add(Conv2D(filters = 512, kernel_size = (1,1), strides=(2, 2), padding = \"same\"))\n",
    "  \n",
    "  # Latent Space\n",
    "  encoder.add(Flatten())\n",
    "  encoder.add(Dense(units = outputUnits))  \n",
    "\n",
    "  return encoder\n",
    "\n",
    "def makeDecoder(inputShape):\n",
    "\n",
    "  # Decoder\n",
    "  \n",
    "  decoder = Sequential()\n",
    "  decoder.add(Input(inputShape))\n",
    "  decoder.add(Reshape((20,20,16)))\n",
    "  \n",
    "  # Convolution Block\n",
    "  decoder.add(Conv2DTranspose(filters = 128, kernel_size = (5,5), strides=(2, 2), padding = \"same\"))\n",
    "  decoder.add(BatchNormalization())\n",
    "  decoder.add(LeakyReLU(alpha = 0.3))\n",
    "\n",
    "  # Convolution Block\n",
    "  decoder.add(Conv2DTranspose(filters = 64, kernel_size = (5,5), strides=(2, 2), padding = \"same\"))\n",
    "  decoder.add(BatchNormalization())\n",
    "  decoder.add(LeakyReLU(alpha = 0.3))\n",
    "\n",
    "  # Convolution Block\n",
    "  decoder.add(Conv2DTranspose(filters = 32, kernel_size = (5,5), strides=(2, 2), padding = \"same\"))\n",
    "  decoder.add(BatchNormalization())\n",
    "  decoder.add(LeakyReLU(alpha = 0.3))\n",
    "\n",
    "  # Convolution Block\n",
    "  decoder.add(Conv2D(filters = 1, kernel_size = (1,1), strides=(1, 1), padding = \"same\"))\n",
    "  #decoder.add(LeakyReLU(alpha = 0.3))\n",
    "  decoder.add(Activation(\"tanh\"))\n",
    "  \n",
    "  return decoder\n",
    "\n",
    "def makeGenerator(input_dim, latent_dim):\n",
    "\n",
    "  encoder = makeEncoder(input_dim, latent_dim)\n",
    "  decoder = makeDecoder((latent_dim,))\n",
    "\n",
    "  input = Input(input_dim)\n",
    "  encoderOutput = encoder(input)\n",
    "  reconstruction = decoder(encoderOutput)\n",
    "\n",
    "  generator = Model(input, reconstruction)\n",
    "\n",
    "  return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "r7ICBxCcBXds"
   },
   "outputs": [],
   "source": [
    "def makeDiscriminator(inputShape):\n",
    "\n",
    "  # Discriminator\n",
    "  discriminator = Sequential()\n",
    "  \n",
    "  # Convolution Block\n",
    "  discriminator.add(Conv2D(filters = 32, kernel_size = (5,5), strides=(2, 2), padding = \"same\" , input_shape = inputShape))\n",
    "  discriminator.add(LeakyReLU(alpha = 0.3))\n",
    "\n",
    "  # Convolution Block\n",
    "  discriminator.add(Conv2D(filters = 64, kernel_size = (5,5), strides=(2, 2), padding = \"same\"))\n",
    "  discriminator.add(BatchNormalization())\n",
    "  discriminator.add(LeakyReLU(alpha = 0.3))\n",
    "\n",
    "  # Convolution Block\n",
    "  discriminator.add(Conv2D(filters = 128, kernel_size = (5,5), strides=(2, 2), padding = \"same\"))\n",
    "  discriminator.add(BatchNormalization())\n",
    "  discriminator.add(LeakyReLU(alpha = 0.3))\n",
    "\n",
    "  # Convolution Block\n",
    "  discriminator.add(Conv2D(filters = 256, kernel_size = (5,5), strides=(2, 2), padding = \"same\"))\n",
    "  discriminator.add(BatchNormalization())\n",
    "  discriminator.add(LeakyReLU(alpha = 0.3))\n",
    "  \n",
    "  discriminator.add(Flatten())\n",
    "  discriminator.add(Dense(units = 1, activation = 'sigmoid' ))\n",
    "\n",
    "  # img = Input(shape = inputShape)\n",
    "  # validity = discriminator(img)\n",
    "\n",
    "  return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FzfjbEfDBZQm"
   },
   "outputs": [],
   "source": [
    "# Change the model path\n",
    "#modelPath = \"/content/drive/MyDrive/PAper2_jou/Models/\"\n",
    "#os.makedirs(modelPath,exist_ok=True)\n",
    "import os\n",
    "modelPath=\"/\"\n",
    "os.makedirs(modelPath,exist_ok=True)\n",
    "os.chdir(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EwnGd--dBVQc"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "# 1 for real images and 0 for fake(generated) ones\n",
    "\n",
    "def discriminator_loss(realImageOut, fakeImageOut):\n",
    "    real_loss = cross_entropy(tf.ones_like(realImageOut), realImageOut)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fakeImageOut), fakeImageOut)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fakeImageOut): # Ask about this\n",
    "    return cross_entropy(tf.ones_like(fakeImageOut), fakeImageOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rUynJ0YdBhrI"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "f54ci50YBuID"
   },
   "outputs": [],
   "source": [
    "input_dim = (160,160,1)\n",
    "latent_dim = 6400\n",
    "BATCH_SIZE = 8 # As total number of training images are 310\n",
    "EPOCHS = 400\n",
    "#trainingDataset = tf.data.Dataset.from_tensor_slices(trainImages).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "HXtuvLqyBjvg"
   },
   "outputs": [],
   "source": [
    "generator = makeGenerator(input_dim, latent_dim)\n",
    "discriminator = makeDiscriminator(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "D1-2TW3oBqBz"
   },
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(modelPath, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer, discriminator_optimizer=discriminator_optimizer, \n",
    "                                generator=generator, discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1PS2SixB2xm",
    "outputId": "e7427f57-bb48-4bfa-9e12-268a120d5575"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f4fd3bc97c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To restore a checkpoint\n",
    "checkpoint.restore(tf.train.latest_checkpoint(modelPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "YAdXWhJtIckt"
   },
   "outputs": [],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def gen_loss1(fake_image,real_image):\n",
    "  return(mse(fake_image,real_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "d4zSVBrDB4b6"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "  \n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "\n",
    "    generated_images = generator(images, training = True)\n",
    "\n",
    "    real_output = discriminator(images, training = True)\n",
    "    fake_output = discriminator(generated_images, training = True)\n",
    "    gen_loss= gen_loss1(generated_images,images)\n",
    "    #gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    \n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    \n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "  return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = \"/Train/*/*\"\n",
    "test_directory  = \"/Test/*/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob.glob(train_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "trainingDataset=create_dataset(train_directory,batch_size=BATCH_SIZE,shuffle=False)\n",
    "for epoch in tqdm(range(200,300)):\n",
    "  \n",
    "  epochStartTime = time.time()\n",
    "\n",
    "  generatorLossList = []\n",
    "  discriminatorLossList = []\n",
    "\n",
    "  for image_batch in trainingDataset:\n",
    "    image_batch1=tf.transpose(image_batch,perm=[0,2,3,1])\n",
    "    t = train_step(image_batch1)\n",
    "    generatorLossList.append(t[0])\n",
    "    discriminatorLossList.append(t[1])\n",
    "\n",
    "  g_loss = sum(generatorLossList) / len(generatorLossList)\n",
    "  d_loss = sum(discriminatorLossList) / len(discriminatorLossList)\n",
    "\n",
    "  timeElapsed = time.time()-epochStartTime\n",
    "  print (\"Epoch = {}, Generator Loss = {:.7f}, Discriminator Loss = {:.7f}, \".format(epoch+1, g_loss, d_loss) + \"Epoch Time : \" + hms_string(timeElapsed))\n",
    "\n",
    "  if((epoch+1)%1==0):  # Save at each 20 epochs\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    generator.save('generator{:03d}.h5'.format(epoch+1))\n",
    "    discriminator.save('discriminator{:03d}.h5'.format(epoch+1))\n",
    "\n",
    "    print(\"Models saved at {} epochs\".format(epoch+1))\n",
    "\n",
    "\n",
    "elapsed = time.time()-start\n",
    "print (\"Total Training time: \" + hms_string(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "generator=tf.keras.models.load_model('')\n",
    "discriminator=tf.keras.models.load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d51u5x7zFrkT",
    "outputId": "10e211ca-b8bb-4993-eff5-1c170f696b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([31, 1, 160, 160]), TensorShape([31, 160, 160, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch.shape,image_batch1.shape\n",
    "#type(image_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "#import mxnet as mx\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "#from mxnet import gluon,nd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# create dataloader (batch_size, 1, 100, 100)\n",
    "def create_dataset(path, file,batch_size, shuffle):\n",
    "  #files = glob.glob(path)\n",
    "  files=sorted(file)\n",
    "  data = np.zeros((len(files),1,160,160))\n",
    "\n",
    "  for idx, filename in enumerate(files):\n",
    "    im = Image.open(filename)\n",
    "    im = ImageOps.grayscale(im)\n",
    "    im = im.resize((160,160))\n",
    "    data[idx,0,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "\n",
    "  #dataset = gluon.data.ArrayDataset(mx.nd.array(data, dtype=np.float32))\n",
    "  #dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch=\"rollover\", shuffle=shuffle)\n",
    "  dataloader = tf.data.Dataset.from_tensor_slices(data).batch(batch_size)\n",
    "\n",
    "  return dataloader\n",
    "\n",
    "# create dataloader (batch_size, 10, 227, 227)\n",
    "def create_dataset_stacked_images(path, batch_size, shuffle, augment=True):\n",
    "  #files=sorted(file)\n",
    "  files = sorted(glob.glob(path))\n",
    "  if augment:\n",
    "    files = files + files[2:] + files[4:] + files[6:] + files[8:]\n",
    "  data = np.zeros((int(len(files)/10),10,160,160))\n",
    "  i, idx = 0, 0\n",
    "  for filename in files:\n",
    "    im = Image.open(filename)\n",
    "    im = im.resize((160,160))\n",
    "    data[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "    i = i + 1\n",
    "    if i > 9: \n",
    "      i = 0\n",
    "      idx = idx + 1\n",
    "  #dataset = gluon.data.ArrayDataset(mx.nd.array(data, dtype=np.float32))\n",
    "  #dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch=\"rollover\", shuffle=shuffle)\n",
    "  dataloader = tf.data.Dataset.from_tensor_slices(data).batch(batch_size)\n",
    "\n",
    "  return dataloader\n",
    "\n",
    "# perform inference and plot results\n",
    "def plot_images(counter,path, model, file,output_path=\"img\", stacked=False, lstm=False):\n",
    "\n",
    "  if not stacked:\n",
    "    dataloader = create_dataset(path, file,batch_size=1, shuffle=False)\n",
    "  else:\n",
    "    dataloader = create_dataset_stacked_images(path, batch_size=1, shuffle=False, augment=False)\n",
    "\n",
    "  #counter = 0\n",
    "  #model.load_parameters(params_file, ctx=ctx)\n",
    "  \n",
    "  try:\n",
    "    os.mkdir(output_path,exist_ok=True)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  for image in dataloader:\n",
    "    \n",
    "    # perform inference\n",
    "    #image = image.as_in_context(ctx)\n",
    "    #if not lstm:\n",
    "      #image_batch1=tf.transpose(image_batch,perm=[0,2,3,1])\n",
    "      #reconstructed = model(image)\n",
    "    #else:\n",
    "      #states = model.temporal_encoder.begin_state(batch_size=1, ctx=ctx)\n",
    "      #reconstructed, states = model(image, states)\n",
    "    #compute difference between reconstructed image and input image \n",
    "    #reconstructed = reconstructed.asnumpy()\n",
    "    #image = image.asnumpy()\n",
    "    #diff = np.abs(reconstructed-image)\n",
    "\n",
    "    if not lstm:\n",
    "      image_batch1=tf.transpose(image,perm=[0,2,3,1])\n",
    "      reconstructed = model(image_batch1)\n",
    "    else:\n",
    "      states = model.temporal_encoder.begin_state(batch_size=1, ctx=ctx)\n",
    "      reconstructed, states = model(image, states)\n",
    "    #compute difference between reconstructed image and input image \n",
    "    reconstructed = reconstructed.numpy()#tf.make_ndarray(reconstructed)\n",
    "    image_batch1 = image_batch1.numpy()\n",
    "    diff = np.abs(reconstructed-image_batch1)\n",
    "    reconstructed=tf.transpose(reconstructed,perm=[0,3,1,2])\n",
    "    diff=np.transpose(diff,(0,3,1,2))\n",
    "    #image\n",
    "    # in case of stacked frames, we need to compute the regularity score per pixel\n",
    "    if stacked:\n",
    "       image    = np.sum(image, axis=1, keepdims=True)\n",
    "       reconstructed = np.sum(reconstructed, axis=1, keepdims=True)\n",
    "       diff_max = np.max(diff, axis=1)\n",
    "       diff_min = np.min(diff, axis=1)\n",
    "       regularity = diff_max - diff_min\n",
    "       # perform convolution on regularity matrix\n",
    "       H = signal.convolve2d(regularity[0,:,:], np.ones((4,4)), mode='same')\n",
    "    else:\n",
    "      # perform convolution on diff matrix\n",
    "      H = signal.convolve2d(diff[0,0,:,:], np.ones((4,4)), mode='same')\n",
    "    \n",
    "    # if neighboring pixels are anamolous, then mark the current pixel\n",
    "    x,y = np.where(H > 4)\n",
    "\n",
    "    # plt input image, reconstructed image and difference between both\n",
    "    fig, (ax0, ax1, ax2,ax3) = plt.subplots(ncols=4, figsize=(10, 5))\n",
    "    ax0.set_axis_off()\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    ax0.imshow(image[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax0.set_title('input image')\n",
    "    ax1.imshow(reconstructed[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax1.set_title('reconstructed image')\n",
    "    ax2.imshow(diff[0,0,:,:], cmap=plt.cm.viridis, vmin=0, vmax=1, interpolation='nearest')\n",
    "    ax2.set_title('diff ')\n",
    "    ax3.imshow(image[0,0,:,:], cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax3.scatter(y,x,color='red',s=0.3)\n",
    "    ax3.set_title('anomalies')\n",
    "    plt.axis('off')\n",
    "    \n",
    "     # save figure\n",
    "    counter = counter + 1\n",
    "    fig.savefig(output_path + \"/\" + str(counter) + '.png', bbox_inches = 'tight', pad_inches = 0.5)\n",
    "    plt.close(fig)\n",
    "  return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob.glob(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22850"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)\n",
    "files=sorted(files)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 46)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files[0:10])\n",
    "range(int(len(files)/500) +1)\n",
    "#len(files[22000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbCuPTlHWW2o",
    "outputId": "2ced5527-4202-446c-a873-9a8de552769b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "generator=tf.keras.models.load_model('generator299.h5')\n",
    "discriminator=tf.keras.models.load_model('discriminator299.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubfaE7hnKDcG"
   },
   "outputs": [],
   "source": [
    "model=generator\n",
    "output_path='/'\n",
    "os.makedirs(output_path,exist_ok=True)\n",
    "plot_images( train_directory, model,output_path)# params_file, ctx, )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Paper2_jou_new_Avenue.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
