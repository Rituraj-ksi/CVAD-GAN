{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import smart_resize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io as scio\n",
    "\n",
    "import natsort\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from yacs.config import CfgNode as CN\n",
    "\n",
    "\n",
    "_C = CN()\n",
    "\n",
    "_C.OUTPUT_DIR = 'output'\n",
    "_C.LOG_DIR = 'log'\n",
    "_C.GPUS = (0, 1, 2, 3)\n",
    "_C.WORKERS = 2\n",
    "_C.PRINT_FREQ = 50\n",
    "_C.SAVE_CHECKPOINT_FREQ = 5\n",
    "_C.AUTO_RESUME = False\n",
    "_C.PIN_MEMORY = True\n",
    "\n",
    "# Cudnn related params\n",
    "_C.CUDNN = CN()\n",
    "_C.CUDNN.BENCHMARK = True\n",
    "_C.CUDNN.DETERMINISTIC = False\n",
    "_C.CUDNN.ENABLED = True\n",
    "\n",
    "\n",
    "# DATASET related params\n",
    "_C.DATASET = CN()\n",
    "_C.DATASET.ROOT = 'datasets'\n",
    "_C.DATASET.DATASET = 'UCSDped2'\n",
    "_C.DATASET.TRAINSET = 'Train'\n",
    "_C.DATASET.TESTSET = 'Test'\n",
    "_C.DATASET.NUM_INCHANNELS = 3\n",
    "_C.DATASET.NUM_FRAMES = 1\n",
    "_C.DATASET.FRAME_STEPS = 1\n",
    "_C.DATASET.LOWER_BOUND = 500\n",
    "\n",
    "\n",
    "# train\n",
    "_C.TRAIN = CN()\n",
    "\n",
    "_C.TRAIN.BATCH_SIZE_PER_GPU = 1\n",
    "_C.TRAIN.SHUFFLE = True\n",
    "\n",
    "_C.TRAIN.BEGIN_EPOCH = 0\n",
    "_C.TRAIN.END_EPOCH = 200\n",
    "_C.TRAIN.RESUME = True\n",
    "_C.TRAIN.CHECKPOINT = ''\n",
    "\n",
    "_C.TRAIN.OPTIMIZER = 'adam'\n",
    "\n",
    "# sgd and\n",
    "_C.TRAIN.MOMENTUM = 0.0\n",
    "_C.TRAIN.WD = 0.0\n",
    "_C.TRAIN.NESTEROV = False\n",
    "\n",
    "_C.TRAIN.LR_TYPE = 'linear'     # 'linear'  /   'step'  /   'multistep'\n",
    "_C.TRAIN.LR = 0.0002\n",
    "_C.TRAIN.LR_STEP = [40, 70]\n",
    "_C.TRAIN.LR_FACTOR = 0.5\n",
    "\n",
    "\n",
    "# testing\n",
    "_C.TEST = CN()\n",
    "\n",
    "# size of images for each device\n",
    "_C.TEST.BATCH_SIZE_PER_GPU = 1\n",
    "\n",
    "\n",
    "# common params for NETWORK\n",
    "_C.MODEL = CN()\n",
    "_C.MODEL.NAME = 'CVAD'\n",
    "_C.MODEL.INIT_WEIGHTS = True\n",
    "_C.MODEL.PRETRAINED = ''\n",
    "_C.MODEL.IMAGE_SIZE = [160, 160]  # width * height\n",
    "_C.MODEL.MEMORY_SIZE = 3\n",
    "_C.MODEL.ENCODED_FRAMES = 3\n",
    "_C.MODEL.DECODED_FRAMES = 1\n",
    "# _C.MODEL.SIGMA = 1.5\n",
    "\n",
    "\n",
    "_C.MODEL.EXTRA = CN()\n",
    "_C.MODEL.EXTRA.FINAL_CONV_KERNEL = 1\n",
    "\n",
    "\n",
    "def update_config(cfg, args):\n",
    "    cfg.defrost()\n",
    "    cfg.merge_from_file(args.cfg)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.freeze()\n",
    "\n",
    "\n",
    "import sys\n",
    "with open(\"conf1\", 'w') as f:\n",
    "    print(_C, file=f)\n",
    "config = _C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Label:\n",
    "    def __init__(self, config):\n",
    "        root = config.DATASET.ROOT\n",
    "        dataset_name = config.DATASET.DATASET\n",
    "        if dataset_name == 'shanghai':\n",
    "            self.frame_mask = os.path.join(root, dataset_name, 'test_frame_mask/*')\n",
    "        mat_name = dataset_name + '.mat'\n",
    "\n",
    "        test_set = config.DATASET.TESTSET\n",
    "        self.mat_path = os.path.join(root, dataset_name, test_set, mat_name)\n",
    "        test_dataset_path = os.path.join(root, dataset_name, test_set)\n",
    "        video_folders = (os.listdir(test_dataset_path))\n",
    "        video_folders.sort()\n",
    "        self.video_folders = [os.path.join(test_dataset_path, folder) for folder in video_folders]\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "    def __call__(self):\n",
    "        if self.dataset_name == 'shanghai':\n",
    "            np_list = glob.glob(self.frame_mask)\n",
    "            np_list.sort()\n",
    "\n",
    "            gt = []\n",
    "            for npy in np_list:\n",
    "                gt.append(np.load(npy))\n",
    "\n",
    "            return gt\n",
    "        else:\n",
    "            abnormal_mat = scio.loadmat(self.mat_path, struct_as_record=True, squeeze_me=True)['TestVideoFile']\n",
    "\n",
    "            all_gt = []\n",
    "            for i in range(abnormal_mat.shape[0]):\n",
    "                length = len(os.listdir(self.video_folders[i]))\n",
    "                sub_video_gt = np.zeros((length,), dtype=np.int8)\n",
    "\n",
    "                one_abnormal = abnormal_mat[i]\n",
    "                if one_abnormal.ndim == 2:\n",
    "                    one_abnormal = one_abnormal.reshape((-1))\n",
    "\n",
    "                j = 0\n",
    "                while j < (one_abnormal.shape[0]):\n",
    "                    start = one_abnormal[j] - 1   # TODO\n",
    "                    end = one_abnormal[j+1]\n",
    "                    j += 2\n",
    "                    sub_video_gt[start: end] = 1\n",
    "\n",
    "                all_gt.append(sub_video_gt)\n",
    "\n",
    "            return all_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_power_2(n, base=32.0):\n",
    "    return int(round(n / base) * base)\n",
    "\n",
    "\n",
    "def get_transform(size, method=Image.BICUBIC, normalize=True, toTensor=True):\n",
    "    w, h = size\n",
    "    new_size = [make_power_2(w), make_power_2(h)]\n",
    "\n",
    "    transform_list = [transforms.Resize(new_size, method)]\n",
    "\n",
    "    if toTensor:\n",
    "        transform_list += [transforms.ToTensor()]\n",
    "    if normalize:\n",
    "        transform_list += [transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))]\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "class TestVideo(data.Dataset):\n",
    "    def __init__(self, config, train=False):\n",
    "        super(TestVideo, self).__init__()\n",
    "        self.new_size = [config.MODEL.IMAGE_SIZE[0], config.MODEL.IMAGE_SIZE[1]]\n",
    "        root = config.DATASET.ROOT\n",
    "        dataset_name = config.DATASET.DATASET\n",
    "        test_set = config.DATASET.TESTSET\n",
    "        train_set = config.DATASET.TRAINSET\n",
    "        if train == True:\n",
    "          self.dir = os.path.join(root, dataset_name, train_set)\n",
    "        else:\n",
    "          self.dir = os.path.join(root, dataset_name, test_set)\n",
    "        assert (os.path.exists(self.dir))\n",
    "\n",
    "        self.videos = self._collect_filelist(self.dir)\n",
    "        print(self.dir)\n",
    "\n",
    "        self.num_videos = len(self.videos)\n",
    "\n",
    "    def _collect_filelist(self, root):\n",
    "        include_ext = [\".png\", \".jpg\", \"jpeg\", \".tif\"]\n",
    "        # collect subfolders\n",
    "        dirs = [x[0] for x in os.walk(root, followlinks=True)]  # if not x[0].startswith('.')]\n",
    "        # sort both dirs and individual images\n",
    "        dirs = natsort.natsorted(dirs)\n",
    "\n",
    "        datasets = [\n",
    "            [os.path.join(fdir, el) for el in natsort.natsorted(os.listdir(fdir))\n",
    "             if os.path.isfile(os.path.join(fdir, el))\n",
    "             and not el.startswith('.')\n",
    "             and any([el.endswith(ext) for ext in include_ext])]\n",
    "\n",
    "            for fdir in dirs\n",
    "        ]\n",
    "\n",
    "        return [el for el in datasets if el]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_videos\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        video_name = self.videos[index]\n",
    "\n",
    "        video = []\n",
    "        for name in video_name:\n",
    "            video.append(name)\n",
    "\n",
    "        return {'video': video, 'video_name': video_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frame(name):\n",
    "    transform = get_transform([config.MODEL.IMAGE_SIZE[0], config.MODEL.IMAGE_SIZE[1]])\n",
    "    frame = Image.open(name).convert('RGB')\n",
    "    frame = transform(frame)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr_park(mse):\n",
    "    return 10 * math.log10(1 / mse)\n",
    "\n",
    "\n",
    "def anomaly_score(psnr, max_psnr, min_psnr):\n",
    "    return (psnr - min_psnr) / (max_psnr - min_psnr)\n",
    "\n",
    "\n",
    "def calculate_auc(config, psnr_list, mat):\n",
    "    ef = config.MODEL.ENCODED_FRAMES\n",
    "    df = config.MODEL.DECODED_FRAMES\n",
    "    fp = ef + df  # number of frames to process\n",
    "\n",
    "    scores = np.array([], dtype=np.float)\n",
    "    labels = np.array([], dtype=np.int)\n",
    "    for i in range(len(psnr_list)):\n",
    "        score = anomaly_score(psnr_list[i], np.max(psnr_list[i]), np.min(psnr_list[i]))\n",
    "        scores = np.concatenate((scores, score), axis=0)\n",
    "        labels = np.concatenate((labels, mat[i][fp:]), axis=0)\n",
    "    assert scores.shape == labels.shape, f'Ground truth has {labels.shape[0]} frames, BUT got {scores.shape[0]} detected frames!'\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, scores, pos_label=0)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    return auc, fpr, tpr\n",
    "\n",
    "def resize_img_ds(image):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  shape1 = image.shape\n",
    "  image = image.reshape(shape1[0], shape1[1], 1)\n",
    "  size = (256, 256)\n",
    "  return smart_resize(image, size).reshape(256, 256, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_input(input, train=True):\n",
    "    video = input['video']\n",
    "    video_name = input['video_name']\n",
    "\n",
    "    if train:\n",
    "        inputs = video[:-1]\n",
    "        target = video[-1]\n",
    "        return inputs, target\n",
    "        # return video, video_name\n",
    "    else:   # TODO: bo sung cho test\n",
    "        return video, video_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_any_data = TestVideo\n",
    "get_label = Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_loader = get_label(config)\n",
    "mat = mat_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\\UCSDped2\\Test\n"
     ]
    }
   ],
   "source": [
    "test_dataset = eval('get_any_data')(config, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.TEST.BATCH_SIZE_PER_GPU * 1,\n",
    "    shuffle=False,\n",
    "    num_workers=config.WORKERS,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "\n",
    "class ConvBnRelu(nn.Module):\n",
    "    # https://github.com/lingtengqiu/Deeperlab-pytorch/blob/master/seg_opr/seg_oprs.py\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0):\n",
    "        super(ConvBnRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n",
    "                              stride=stride, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvTransposeBnRelu(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, kernel_size, stride=2):\n",
    "        super(ConvTransposeBnRelu, self).__init__()\n",
    "        if stride != 2:     # ConvTranspose2d with factor = 4\n",
    "            if kernel_size == 4:    # stride == 4\n",
    "                padding = 0\n",
    "                output_padding = 0\n",
    "        else:       # ConvTranspose2d with factor = 2\n",
    "            if kernel_size == 4:\n",
    "                padding = 1\n",
    "                output_padding = 0\n",
    "            elif kernel_size == 3:\n",
    "                padding = 1\n",
    "                output_padding = 1\n",
    "            elif kernel_size == 2:\n",
    "                padding = 0\n",
    "                output_padding = 0\n",
    "        self.ConvTranspose = nn.ConvTranspose2d(in_channels=input_channels, out_channels=output_channels,\n",
    "                                                kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                                output_padding=output_padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(output_channels, momentum=0.1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ConvTranspose(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, input_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, input_channels//reduction, 1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(input_channels//reduction, input_channels, 1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.layer(y)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "class TemporalShift(nn.Module):\n",
    "    def __init__(self, n_segment=4, n_div=8, direction='left'):\n",
    "        super(TemporalShift, self).__init__()\n",
    "        self.n_segment = n_segment\n",
    "        self.fold_div = n_div\n",
    "        self.direction = direction\n",
    "\n",
    "        print('=> Using fold div: {}'.format(self.fold_div))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shift(x, self.n_segment, fold_div=self.fold_div, direction=self.direction)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def shift(x, n_segment=4, fold_div=8, direction='left'):\n",
    "        bz, nt, h, w = x.size()\n",
    "        c = nt // n_segment\n",
    "        x = x.view(bz, n_segment, c, h, w)\n",
    "\n",
    "        fold = c // fold_div\n",
    "\n",
    "        out = torch.zeros_like(x)\n",
    "        if direction == 'left':\n",
    "            out[:, :-1, :fold] = x[:, 1:, :fold]  # shift left\n",
    "            out[:, :, fold:] = x[:, :, fold:]  # not shift\n",
    "        elif direction == 'right':\n",
    "            out[:, 1:, :fold] = x[:, :-1, :fold]  # shift right\n",
    "            out[:, :, fold:] = x[:, :, fold:]  # not shift\n",
    "        else:   # shift left and right\n",
    "            out[:, :-1, :fold] = x[:, 1:, :fold]  # shift left\n",
    "            out[:, 1:, fold: 2 * fold] = x[:, :-1, fold: 2 * fold]  # shift right\n",
    "            out[:, :, 2 * fold:] = x[:, :, 2 * fold:]  # not shift\n",
    "\n",
    "        return out.view(bz, nt, h, w)\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "Norm2d = nn.BatchNorm2d\n",
    "\n",
    "\n",
    "def bnrelu(channels):\n",
    "    \"\"\"\n",
    "    Single Layer BN and Relui\n",
    "    \"\"\"\n",
    "    return nn.Sequential(Norm2d(channels),\n",
    "                         nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Global average pooling over the input's spatial dimensions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "        logging.info(\"Global Average Pooling Initialized\")\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        in_size = inputs.size()\n",
    "        return inputs.view((in_size[0], in_size[1], -1)).mean(dim=2)\n",
    "\n",
    "\n",
    "class IdentityResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Identity Residual Block for WideResnet\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 channels,\n",
    "                 stride=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 norm_act=bnrelu,\n",
    "                 dropout=None,\n",
    "                 dist_bn=False\n",
    "                 ):\n",
    "        \"\"\"Configurable identity-mapping residual block\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_channels : int\n",
    "            Number of input channels.\n",
    "        channels : list of int\n",
    "            Number of channels in the internal feature maps.\n",
    "            Can either have two or three elements: if three construct\n",
    "            a residual block with two `3 x 3` convolutions,\n",
    "            otherwise construct a bottleneck block with `1 x 1`, then\n",
    "            `3 x 3` then `1 x 1` convolutions.\n",
    "        stride : int\n",
    "            Stride of the first `3 x 3` convolution\n",
    "        dilation : int\n",
    "            Dilation to apply to the `3 x 3` convolutions.\n",
    "        groups : int\n",
    "            Number of convolution groups.\n",
    "            This is used to create ResNeXt-style blocks and is only compatible with\n",
    "            bottleneck blocks.\n",
    "        norm_act : callable\n",
    "            Function to create normalization / activation Module.\n",
    "        dropout: callable\n",
    "            Function to create Dropout Module.\n",
    "        dist_bn: Boolean\n",
    "            A variable to enable or disable use of distributed BN\n",
    "        \"\"\"\n",
    "        super(IdentityResidualBlock, self).__init__()\n",
    "        self.dist_bn = dist_bn\n",
    "\n",
    "        # Check parameters for inconsistencies\n",
    "        if len(channels) != 2 and len(channels) != 3:\n",
    "            raise ValueError(\"channels must contain either two or three values\")\n",
    "        if len(channels) == 2 and groups != 1:\n",
    "            raise ValueError(\"groups > 1 are only valid if len(channels) == 3\")\n",
    "\n",
    "        is_bottleneck = len(channels) == 3\n",
    "        need_proj_conv = stride != 1 or in_channels != channels[-1]\n",
    "\n",
    "        self.bn1 = norm_act(in_channels)\n",
    "        if not is_bottleneck:\n",
    "            layers = [\n",
    "                (\"conv1\", nn.Conv2d(in_channels,\n",
    "                                    channels[0],\n",
    "                                    3,\n",
    "                                    stride=stride,\n",
    "                                    padding=dilation,\n",
    "                                    bias=False,\n",
    "                                    dilation=dilation)),\n",
    "                (\"bn2\", norm_act(channels[0])),\n",
    "                (\"conv2\", nn.Conv2d(channels[0], channels[1],\n",
    "                                    3,\n",
    "                                    stride=1,\n",
    "                                    padding=dilation,\n",
    "                                    bias=False,\n",
    "                                    dilation=dilation))\n",
    "            ]\n",
    "            if dropout is not None:\n",
    "                layers = layers[0:2] + [(\"dropout\", dropout())] + layers[2:]\n",
    "        else:\n",
    "            layers = [\n",
    "                (\"conv1\",\n",
    "                 nn.Conv2d(in_channels,\n",
    "                           channels[0],\n",
    "                           1,\n",
    "                           stride=stride,\n",
    "                           padding=0,\n",
    "                           bias=False)),\n",
    "                (\"bn2\", norm_act(channels[0])),\n",
    "                (\"conv2\", nn.Conv2d(channels[0],\n",
    "                                    channels[1],\n",
    "                                    3, stride=1,\n",
    "                                    padding=dilation, bias=False,\n",
    "                                    groups=groups,\n",
    "                                    dilation=dilation)),\n",
    "                (\"bn3\", norm_act(channels[1])),\n",
    "                (\"conv3\", nn.Conv2d(channels[1], channels[2],\n",
    "                                    1, stride=1, padding=0, bias=False))\n",
    "            ]\n",
    "            if dropout is not None:\n",
    "                layers = layers[0:4] + [(\"dropout\", dropout())] + layers[4:]\n",
    "        self.convs = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "        if need_proj_conv:\n",
    "            self.proj_conv = nn.Conv2d(\n",
    "                in_channels, channels[-1], 1, stride=stride, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This is the standard forward function for non-distributed batch norm\n",
    "        \"\"\"\n",
    "        if hasattr(self, \"proj_conv\"):\n",
    "            bn1 = self.bn1(x)\n",
    "            shortcut = self.proj_conv(bn1)\n",
    "        else:\n",
    "            shortcut = x.clone()\n",
    "            bn1 = self.bn1(x)\n",
    "\n",
    "        out = self.convs(bn1)\n",
    "        out.add_(shortcut)\n",
    "        return out\n",
    "\n",
    "\n",
    "class WiderResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    WideResnet Global Module for Initialization\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 structure,\n",
    "                 norm_act=bnrelu,\n",
    "                 classes=0\n",
    "                 ):\n",
    "        \"\"\"Wider ResNet with pre-activation (identity mapping) blocks\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        structure : list of int\n",
    "            Number of residual blocks in each of the six modules of the network.\n",
    "        norm_act : callable\n",
    "            Function to create normalization / activation Module.\n",
    "        classes : int\n",
    "            If not `0` also include global average pooling and \\\n",
    "            a fully-connected layer with `classes` outputs at the end\n",
    "            of the network.\n",
    "        \"\"\"\n",
    "        super(WiderResNet, self).__init__()\n",
    "        self.structure = structure\n",
    "\n",
    "        if len(structure) != 6:\n",
    "            raise ValueError(\"Expected a structure with six values\")\n",
    "\n",
    "        # Initial layers\n",
    "        self.mod1 = nn.Sequential(OrderedDict([\n",
    "            (\"conv1\", nn.Conv2d(3, 64, 3, stride=1, padding=1, bias=False))\n",
    "        ]))\n",
    "\n",
    "        # Groups of residual blocks\n",
    "        in_channels = 64\n",
    "        channels = [(128, 128), (256, 256), (512, 512), (512, 1024),\n",
    "                    (512, 1024, 2048), (1024, 2048, 4096)]\n",
    "        for mod_id, num in enumerate(structure):\n",
    "            # Create blocks for module\n",
    "            blocks = []\n",
    "            for block_id in range(num):\n",
    "                blocks.append((\n",
    "                    \"block%d\" % (block_id + 1),\n",
    "                    IdentityResidualBlock(in_channels, channels[mod_id],\n",
    "                                          norm_act=norm_act)\n",
    "                ))\n",
    "\n",
    "                # Update channels and p_keep\n",
    "                in_channels = channels[mod_id][-1]\n",
    "\n",
    "            # Create module\n",
    "            if mod_id <= 4:\n",
    "                self.add_module(\"pool%d\" %\n",
    "                                (mod_id + 2), nn.MaxPool2d(3, stride=2, padding=1))\n",
    "            self.add_module(\"mod%d\" % (mod_id + 2), nn.Sequential(OrderedDict(blocks)))\n",
    "\n",
    "        # Pooling and predictor\n",
    "        self.bn_out = norm_act(in_channels)\n",
    "        if classes != 0:\n",
    "            self.classifier = nn.Sequential(OrderedDict([\n",
    "                (\"avg_pool\", GlobalAvgPool2d()),\n",
    "                (\"fc\", nn.Linear(in_channels, classes))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.mod1(img)\n",
    "        out = self.mod2(self.pool2(out))\n",
    "        out = self.mod3(self.pool3(out))\n",
    "        out = self.mod4(self.pool4(out))\n",
    "        out = self.mod5(self.pool5(out))\n",
    "        out = self.mod6(self.pool6(out))\n",
    "        out = self.mod7(out)\n",
    "        out = self.bn_out(out)\n",
    "\n",
    "        if hasattr(self, \"classifier\"):\n",
    "            out = self.classifier(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class WiderResNetA2(nn.Module):\n",
    "    \"\"\"\n",
    "    Wider ResNet with pre-activation (identity mapping) blocks\n",
    "\n",
    "    This variant uses down-sampling by max-pooling in the first two blocks and\n",
    "     by strided convolution in the others.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    structure : list of int\n",
    "        Number of residual blocks in each of the six modules of the network.\n",
    "    norm_act : callable\n",
    "        Function to create normalization / activation Module.\n",
    "    classes : int\n",
    "        If not `0` also include global average pooling and a fully-connected layer\n",
    "        with `classes` outputs at the end\n",
    "        of the network.\n",
    "    dilation : bool\n",
    "        If `True` apply dilation to the last three modules and change the\n",
    "        down-sampling factor from 32 to 8.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 structure,\n",
    "                 norm_act=bnrelu,\n",
    "                 classes=0,\n",
    "                 dilation=False,\n",
    "                 dist_bn=False\n",
    "                 ):\n",
    "        super(WiderResNetA2, self).__init__()\n",
    "        self.dist_bn = dist_bn\n",
    "\n",
    "        # If using distributed batch norm, use the encoding.nn as oppose to torch.nn\n",
    "        nn.Dropout = nn.Dropout2d\n",
    "        norm_act = bnrelu\n",
    "        self.structure = structure\n",
    "        self.dilation = dilation\n",
    "\n",
    "        if len(structure) != 6:\n",
    "            raise ValueError(\"Expected a structure with six values\")\n",
    "\n",
    "        # Initial layers\n",
    "        self.mod1 = torch.nn.Sequential(OrderedDict([\n",
    "            (\"conv1\", nn.Conv2d(3, 64, 3, stride=1, padding=1, bias=False))\n",
    "        ]))\n",
    "\n",
    "        # Groups of residual blocks\n",
    "        in_channels = 64\n",
    "        channels = [(128, 128), (256, 256), (512, 512), (512, 1024), (512, 1024, 2048),\n",
    "                    (1024, 2048, 4096)]\n",
    "        for mod_id, num in enumerate(structure):\n",
    "            # Create blocks for module\n",
    "            blocks = []\n",
    "            for block_id in range(num):\n",
    "                if not dilation:\n",
    "                    dil = 1\n",
    "                    stride = 2 if block_id == 0 and 2 <= mod_id <= 4 else 1\n",
    "                else:\n",
    "                    if mod_id == 3:\n",
    "                        dil = 2\n",
    "                    elif mod_id > 3:\n",
    "                        dil = 4\n",
    "                    else:\n",
    "                        dil = 1\n",
    "                    stride = 2 if block_id == 0 and mod_id == 2 else 1\n",
    "\n",
    "                if mod_id == 4:\n",
    "                    drop = partial(nn.Dropout, p=0.3)\n",
    "                elif mod_id == 5:\n",
    "                    drop = partial(nn.Dropout, p=0.5)\n",
    "                else:\n",
    "                    drop = None\n",
    "\n",
    "                blocks.append((\n",
    "                    \"block%d\" % (block_id + 1),\n",
    "                    IdentityResidualBlock(in_channels,\n",
    "                                          channels[mod_id], norm_act=norm_act,\n",
    "                                          stride=stride, dilation=dil,\n",
    "                                          dropout=drop, dist_bn=self.dist_bn)\n",
    "                ))\n",
    "\n",
    "                # Update channels and p_keep\n",
    "                in_channels = channels[mod_id][-1]\n",
    "\n",
    "            # Create module\n",
    "            if mod_id < 2:\n",
    "                self.add_module(\"pool%d\" %\n",
    "                                (mod_id + 2), nn.MaxPool2d(3, stride=2, padding=1))\n",
    "            self.add_module(\"mod%d\" % (mod_id + 2), nn.Sequential(OrderedDict(blocks)))\n",
    "\n",
    "        # Pooling and predictor\n",
    "        self.bn_out = norm_act(in_channels)\n",
    "        if classes != 0:\n",
    "            self.classifier = nn.Sequential(OrderedDict([\n",
    "                (\"avg_pool\", GlobalAvgPool2d()),\n",
    "                (\"fc\", nn.Linear(in_channels, classes))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.mod1(img)\n",
    "        out = self.mod2(self.pool2(out))   # s2\n",
    "        out = self.mod3(self.pool3(out))   # s4\n",
    "        out = self.mod4(out)               # s8\n",
    "        out = self.mod5(out)\n",
    "        out = self.mod6(out)\n",
    "        out = self.mod7(out)\n",
    "        out = self.bn_out(out)\n",
    "\n",
    "        if hasattr(self, \"classifier\"):\n",
    "            return self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "_NETS = {\n",
    "    \"16\": {\"structure\": [1, 1, 1, 1, 1, 1]},\n",
    "    \"20\": {\"structure\": [1, 1, 1, 3, 1, 1]},\n",
    "    \"38\": {\"structure\": [3, 3, 6, 3, 1, 1]},\n",
    "}\n",
    "\n",
    "__all__ = []\n",
    "for name, params in _NETS.items():\n",
    "    net_name = \"wider_resnet\" + name\n",
    "    setattr(sys.modules[__name__], net_name, partial(WiderResNet, **params))\n",
    "    __all__.append(net_name)\n",
    "for name, params in _NETS.items():\n",
    "    net_name = \"wider_resnet\" + name + \"_a2\"\n",
    "    setattr(sys.modules[__name__], net_name, partial(WiderResNetA2, **params))\n",
    "    __all__.append(net_name)\n",
    "\n",
    "\n",
    "class wrn38(nn.Module):\n",
    "    \"\"\"\n",
    "    This is wider resnet 38, output_stride=8\n",
    "    \"\"\"\n",
    "    def __init__(self, config, pretrained=True):\n",
    "        super(wrn38, self).__init__()\n",
    "        wide_resnet = wider_resnet38_a2(classes=1000, dilation=True)\n",
    "        wide_resnet = torch.nn.DataParallel(wide_resnet)\n",
    "        # if pretrained:\n",
    "        #     pretrained_model = config.MODEL.PRETRAINED\n",
    "        #     checkpoint = torch.load(pretrained_model, map_location='cpu')\n",
    "        #     wide_resnet.load_state_dict(checkpoint['state_dict'])\n",
    "        #     del checkpoint\n",
    "        wide_resnet = wide_resnet.module\n",
    "        # print(wide_resnet)\n",
    "        self.mod1 = wide_resnet.mod1\n",
    "        self.mod2 = wide_resnet.mod2\n",
    "        self.mod3 = wide_resnet.mod3\n",
    "        self.mod4 = wide_resnet.mod4\n",
    "        self.mod5 = wide_resnet.mod5\n",
    "        self.mod6 = wide_resnet.mod6\n",
    "        self.mod7 = wide_resnet.mod7\n",
    "        self.pool2 = wide_resnet.pool2\n",
    "        self.pool3 = wide_resnet.pool3\n",
    "        del wide_resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mod1(x)\n",
    "        x = self.mod2(self.pool2(x))   # s2\n",
    "        s2_features = x\n",
    "        x = self.mod3(self.pool3(x))   # s4\n",
    "        s4_features = x\n",
    "        x = self.mod4(x)\n",
    "        x = self.mod5(x)\n",
    "        x = self.mod6(x)\n",
    "        x = self.mod7(x)\n",
    "        return s2_features, s4_features, x\n",
    "\n",
    "\n",
    "def wresnet(config, name, pretrained=True):\n",
    "    if name == 'wrn38':\n",
    "        return wrn38(config, pretrained=True)\n",
    "    else:\n",
    "        raise ValueError(\"Not a valid network arch\")\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ASTNet(nn.Module):\n",
    "    def get_name(self):\n",
    "        return self.model_name\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(ASTNet, self).__init__()\n",
    "        frames = config.MODEL.ENCODED_FRAMES\n",
    "        final_conv_kernel = config.MODEL.EXTRA.FINAL_CONV_KERNEL\n",
    "        self.model_name = config.MODEL.NAME\n",
    "        print(self.model_name)\n",
    "\n",
    "        logger.info('=> ' + self.model_name + '_1024: (CATTN + TSM) - Ped2')\n",
    "\n",
    "        self.wrn38 = wresnet(config, self.model_name, pretrained=False)\n",
    "\n",
    "        channels = [4096, 2048, 1024, 512, 256, 128]\n",
    "\n",
    "        self.conv_x8 = nn.Conv2d(channels[0] * frames, channels[1], kernel_size=1, bias=False)\n",
    "        self.conv_x2 = nn.Conv2d(channels[4] * frames, channels[4], kernel_size=1, bias=False)\n",
    "        self.conv_x1 = nn.Conv2d(channels[5] * frames, channels[5], kernel_size=1, bias=False)\n",
    "\n",
    "        self.up8 = ConvTransposeBnRelu(channels[1], channels[2], kernel_size=2)   # 2048          -> 1024\n",
    "        self.up4 = ConvTransposeBnRelu(channels[2] + channels[4], channels[3], kernel_size=2)   # 1024  +   256 -> 512\n",
    "        self.up2 = ConvTransposeBnRelu(channels[3] + channels[5], channels[4], kernel_size=2)   # 512   +   128 -> 256\n",
    "\n",
    "        self.tsm_left = TemporalShift(n_segment=4, n_div=16, direction='left')\n",
    "\n",
    "        self.attn8 = ChannelAttention(channels[2])\n",
    "        self.attn4 = ChannelAttention(channels[3])\n",
    "        self.attn2 = ChannelAttention(channels[4])\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            ConvBnRelu(channels[4], channels[5], kernel_size=1, padding=0),\n",
    "            ConvBnRelu(channels[5], channels[5], kernel_size=3, padding=1),\n",
    "            nn.Conv2d(channels[5], 3,\n",
    "                      kernel_size=final_conv_kernel,\n",
    "                      padding=1 if final_conv_kernel == 3 else 0,\n",
    "                      bias=False)\n",
    "        )\n",
    "\n",
    "        initialize_weights(self.conv_x1, self.conv_x2, self.conv_x8)\n",
    "        initialize_weights(self.up2, self.up4, self.up8)\n",
    "        initialize_weights(self.attn2, self.attn4, self.attn8)\n",
    "        initialize_weights(self.final)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1s, x2s, x8s = [], [], []\n",
    "        for xi in x:\n",
    "            x1, x2, x8 = self.wrn38(xi)\n",
    "            x8s.append(x8)\n",
    "            x2s.append(x2)\n",
    "            x1s.append(x1)\n",
    "\n",
    "        x8 = self.conv_x8(torch.cat(x8s, dim=1))\n",
    "        x2 = self.conv_x2(torch.cat(x2s, dim=1))\n",
    "        x1 = self.conv_x1(torch.cat(x1s, dim=1))\n",
    "\n",
    "        left = self.tsm_left(x8)\n",
    "        x8 = x8 + left\n",
    "\n",
    "        x = self.up8(x8)                            # 2048          -> 1024, 24, 40\n",
    "        x = self.attn8(x)\n",
    "        x = self.up4(torch.cat([x2, x], dim=1))     # 1024 + 256    -> 512, 48, 80\n",
    "        x = self.attn4(x)\n",
    "\n",
    "        x = self.up2(torch.cat([x1, x], dim=1))     # 512 + 128     -> 256, 96, 160\n",
    "        x = self.attn2(x)\n",
    "\n",
    "        return self.final(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained models\n",
    "netG = torch.load('models/peds2-cvad-generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_gpu_cache():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inference(config, data_loader, model):\n",
    "    loss_func_mse = nn.MSELoss(reduction='none')\n",
    "\n",
    "    model.eval()\n",
    "    psnr_list = []\n",
    "    mse_list = []\n",
    "    ef = config.MODEL.ENCODED_FRAMES\n",
    "    df = config.MODEL.DECODED_FRAMES\n",
    "    fp = ef + df\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_loader):\n",
    "            print('[{}/{}]'.format(i+1, len(data_loader)))\n",
    "            psnr_video = []\n",
    "            mse_video = []\n",
    "\n",
    "            vids, video_name = decode_input(input=data, train=False)\n",
    "            for f in tqdm(range(len(vids) - fp)):\n",
    "                # buffer\n",
    "                video = []\n",
    "                for name in vids[f:f+fp]:\n",
    "                  reshaped_frame = torch.reshape(read_frame(name[0]), (1, 3, config.MODEL.IMAGE_SIZE[0], config.MODEL.IMAGE_SIZE[1]))\n",
    "                  video.append(reshaped_frame.to(device=config.GPUS[0]))\n",
    "                inputs = video[0:ef]\n",
    "                output = model(inputs)\n",
    "                target = video[ef:fp][0]\n",
    "\n",
    "                del video, inputs\n",
    "\n",
    "\n",
    "            #     # compute PSNR for each frame\n",
    "                mse_imgs = torch.mean(loss_func_mse((output[0] + 1) / 2, (target[0] + 1) / 2)).item()\n",
    "                psnr = psnr_park(mse_imgs)\n",
    "                psnr_video.append(psnr)\n",
    "                mse_video.append(mse_imgs)\n",
    "\n",
    "                del output, target\n",
    "            free_gpu_cache()\n",
    "\n",
    "            psnr_list.append(psnr_video)\n",
    "            mse_list.append(mse_video)\n",
    "    return psnr_list, mse_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results'):\n",
    "  os.mkdir('results')\n",
    "\n",
    "psnr_list, mse_list = inference(config, test_loader, netG)\n",
    "assert len(psnr_list) == len(mat), f'Ground truth has {len(mat)} videos, BUT got {len(psnr_list)} detected videos!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc, fpr, tpr = calculate_auc(config, psnr_list, mat)\n",
    "# breakpoint()\n",
    "print(f'AUC: {auc * 100:.1f}%' )\n",
    "np.save('results/fpr_list.npy', fpr)  \n",
    "np.save('results/tpr_list.npy', tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-keras-gpu-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
